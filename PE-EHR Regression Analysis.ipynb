{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1545a76c-d851-4fd6-862b-94ae4668dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are Tanmayee and Grey and our final project is on Pulmonary Embolism based on the EHR dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"We are Tanmayee and Grey and our final project is on Pulmonary Embolism based on the EHR dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c9d78b-dcca-4ef3-861c-c768643cf868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, fisher_exact, f_oneway, kruskal, shapiro, levene\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.contingency_tables import Table2x2\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9cc60e-2616-4be0-9d75-38279949d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1713, 39)\n",
      "   Index    Group  PE_in_index_hospitalization   Age_groups     Sex  Diabetes  \\\n",
      "0    1.0  Group-1                           1.0         6.0  Female       0.0   \n",
      "1    2.0  Group-1                           1.0         4.0  Female       0.0   \n",
      "2    3.0  Group-3                           0.0         6.0  Female       0.0   \n",
      "3    4.0  Group-2                           0.0         7.0  Female       0.0   \n",
      "4    5.0  Group-3                           0.0         6.0    Male       0.0   \n",
      "\n",
      "   Hypertension  History of CVA  Heart Failure  Dialysis  CAD  \\\n",
      "0           1.0             0.0            1.0       0.0  1.0   \n",
      "1           0.0             0.0            0.0       0.0  0.0   \n",
      "2           0.0             0.0            0.0       0.0  0.0   \n",
      "3           1.0             0.0            0.0       0.0  0.0   \n",
      "4           1.0             0.0            0.0       0.0  0.0   \n",
      "\n",
      "   Prior Hx of VTE  COVID-19 in Prior 30-days  PAD  Non-Hispanic White  \\\n",
      "0              0.0                        0.0  0.0                 1.0   \n",
      "1              0.0                        0.0  0.0                 1.0   \n",
      "2              0.0                        0.0  0.0                 1.0   \n",
      "3              1.0                        0.0  0.0                 1.0   \n",
      "4              0.0                        0.0  0.0                 0.0   \n",
      "\n",
      "   Non-Hispanic Black  Non-Hispanic Asian  Non-Hispanic Other or Unknown  \\\n",
      "0                 0.0                 0.0                            0.0   \n",
      "1                 0.0                 0.0                            0.0   \n",
      "2                 0.0                 0.0                            0.0   \n",
      "3                 0.0                 0.0                            0.0   \n",
      "4                 1.0                 0.0                            0.0   \n",
      "\n",
      "   Hispanic/Latinx  American Indian or Alaska Native  \\\n",
      "0              0.0                               0.0   \n",
      "1              0.0                               0.0   \n",
      "2              0.0                               0.0   \n",
      "3              0.0                               0.0   \n",
      "4              0.0                               0.0   \n",
      "\n",
      "   Native Hawaiian or Other Pacific Islander  Other races/ethnicities  \\\n",
      "0                                        0.0                      0.0   \n",
      "1                                        0.0                      0.0   \n",
      "2                                        0.0                      0.0   \n",
      "3                                        0.0                      0.0   \n",
      "4                                        0.0                      0.0   \n",
      "\n",
      "   Unknown/Declined race/ethnicity Principal_Discharge_Dx_ICD10  Contact_Year  \\\n",
      "0                              0.0                       I26.99        2020.0   \n",
      "1                              0.0                       I26.99        2016.0   \n",
      "2                              0.0                        T30.0        2021.0   \n",
      "3                              0.0                        K92.2        2021.0   \n",
      "4                              0.0                        C60.9        2019.0   \n",
      "\n",
      "                                 Diagnosis_encounter    ICD10_encounter  \\\n",
      "0                                 Pulmonary embolism             I26.99   \n",
      "1                                 Pulmonary embolism             I26.99   \n",
      "2  Burns of multiple specified sites Burns of mul...  T30.0 T30.0 T30.0   \n",
      "3  Pulmonary embolism, unspecified chronicity, un...             I26.99   \n",
      "4   Hypertensive disorder Hypertension Penile cancer      I10 I10 C60.9   \n",
      "\n",
      "   HospitalAdmission  HospitalDischarge  IfPE_OnlySubsegmental  \\\n",
      "0             2020.0             2020.0                    0.0   \n",
      "1             2016.0             2016.0                    0.0   \n",
      "2             2021.0             2021.0                    0.0   \n",
      "3             2021.0             2021.0                    0.0   \n",
      "4             2019.0             2019.0                    0.0   \n",
      "\n",
      "   IfPE_CorPulmonale  IfCorPulmonale_CT  IfCorPulmonale_Echo  \\\n",
      "0                1.0                0.0                  1.0   \n",
      "1                1.0                1.0                  0.0   \n",
      "2                0.0                0.0                  0.0   \n",
      "3                0.0                0.0                  0.0   \n",
      "4                0.0                0.0                  0.0   \n",
      "\n",
      "   IfCorPulmonale_Troponin  CTPA  CT_chest  VP_scan  PulmonaryAngio  \\\n",
      "0                      0.0     1         1        0               0   \n",
      "1                      0.0     1         0        0               0   \n",
      "2                      0.0     0         0        0               0   \n",
      "3                      0.0     0         1        0               0   \n",
      "4                      0.0     0         0        0               0   \n",
      "\n",
      "   RadiologyConsult  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n"
     ]
    }
   ],
   "source": [
    "# For .xlsx files (Excel)\n",
    "df = pd.read_excel('data/pe_dataset.xlsx', sheet_name='Dataset')\n",
    "\n",
    "print(df.shape)  # Shows (number_of_rows, number_of_columns)\n",
    "print(df.head())  # Shows first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0717783e-2964-4a6e-89d5-59cff6d134e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created Age_Category variable\n",
      "✓ Created Additional_Procedures and Excessive_Diagnostics variables\n",
      "✓ Created Race_Ethnicity variable\n"
     ]
    }
   ],
   "source": [
    "# 2.1: Collapsed age groups for analysis\n",
    "def categorize_age(Age_groups):\n",
    "    \"\"\"Collapse 9 age categories into 4 research categories\"\"\"\n",
    "    if Age_groups in [1, 2, 3]:\n",
    "        return '<40'\n",
    "    elif Age_groups in [4, 5]:\n",
    "        return '40-60'\n",
    "    elif Age_groups == 6:\n",
    "        return '60-75'\n",
    "    elif Age_groups in [7, 8, 9]:\n",
    "        return '>75'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['Age_Category'] = df['Age_groups'].apply(categorize_age)\n",
    "print(f\"✓ Created Age_Category variable\")\n",
    "\n",
    "# 2.2: Create count of additional diagnostic procedures (excluding CTPA)\n",
    "# Count non-CTPA procedures: CT_chest + VP_scan + PulmonaryAngio\n",
    "df['Additional_Procedures'] = (\n",
    "    df['CT_chest'].fillna(0) + \n",
    "    df['VP_scan'].fillna(0) + \n",
    "    df['PulmonaryAngio'].fillna(0)\n",
    ")\n",
    "\n",
    "# 2.3: Create binary \"Excessive Diagnostics\" variable (>1 additional test)\n",
    "df['Excessive_Diagnostics'] = (df['Additional_Procedures'] > 1).astype(int)\n",
    "print(f\"✓ Created Additional_Procedures and Excessive_Diagnostics variables\")\n",
    "\n",
    "# 2.4: Create consolidated race/ethnicity variable (collapse small groups if needed)\n",
    "# This is a placeholder - you may want to collapse categories based on sample sizes\n",
    "df['Race_Ethnicity'] = 'Unknown'  # Initialize\n",
    "\n",
    "# Map race/ethnicity (modify based on your actual column names)\n",
    "df.loc[df['Non-Hispanic White'] == 1, 'Race_Ethnicity'] = 'Non-Hispanic White'\n",
    "df.loc[df['Non-Hispanic Black'] == 1, 'Race_Ethnicity'] = 'Non-Hispanic Black'\n",
    "df.loc[df['Non-Hispanic Asian'] == 1, 'Race_Ethnicity'] = 'Non-Hispanic Asian'\n",
    "df.loc[df['Hispanic/Latinx'] == 1, 'Race_Ethnicity'] = 'Hispanic/Latinx'\n",
    "df.loc[df['American Indian or Alaska Native'] == 1, 'Race_Ethnicity'] = 'American Indian/Alaska Native'\n",
    "df.loc[df['Native Hawaiian or Other Pacific Islander'] == 1, 'Race_Ethnicity'] = 'Native Hawaiian/Pacific Islander'\n",
    "df.loc[(df['Non-Hispanic Other or Unknown'] == 1) | \n",
    "       (df['Other races/ethnicities'] == 1) | \n",
    "       (df['Unknown/Declined race/ethnicity'] == 1), 'Race_Ethnicity'] = 'Other/Unknown'\n",
    "\n",
    "print(f\"✓ Created Race_Ethnicity variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67b8e8-4965-46c1-a793-2ab43c0ee3fb",
   "metadata": {},
   "source": [
    "AIM 1: AGE GROUP AND PE INCIDENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26db93e5-ec10-43e3-9a52-e90e769c928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP1: DATA PREPARATION AND CLEANING\n",
    "# Clean column names (remove trailing spaces)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Remove rows with missing Age_Category or PE status\n",
    "df_clean = df[df['Age_Category'].notna() & df['PE_in_index_hospitalization'].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b03f12-2dae-4d28-b774-f1f083af7ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Descriptive Statistics\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Table 1: Age Group × PE Status\n",
      "              PE Negative  PE Positive  Total\n",
      "Age_Category                                 \n",
      "40-60                 266          316    582\n",
      "60-75                 189          211    400\n",
      "<40                   217          138    355\n",
      ">75                   177          198    375\n",
      "All                   849          863   1712\n",
      "\n",
      "Table 2: PE Incidence Rates by Age Group\n",
      "                N  PE_Positive  PE_Rate_%\n",
      "Age_Category                             \n",
      "40-60         582        316.0      54.30\n",
      "60-75         400        211.0      52.75\n",
      "<40           355        138.0      38.87\n",
      ">75           375        198.0      52.80\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: DESCRIPTIVE STATISTICS\n",
    "\n",
    "print(\"\\n Descriptive Statistics\")\n",
    "print(\"-\"*80)\n",
    "# Table 1: Crosstabulation\n",
    "crosstab = pd.crosstab(\n",
    "    df_clean['Age_Category'], \n",
    "    df_clean['PE_in_index_hospitalization'],\n",
    "    margins=True\n",
    ")\n",
    "crosstab.columns = ['PE Negative', 'PE Positive', 'Total']\n",
    "print(\"\\nTable 1: Age Group × PE Status\")\n",
    "print(crosstab)\n",
    "\n",
    "# Table 2: PE incidence rates\n",
    "pe_rates = df_clean.groupby('Age_Category')['PE_in_index_hospitalization'].agg([\n",
    "    ('N', 'count'),\n",
    "    ('PE_Positive', 'sum'),\n",
    "    ('PE_Rate_%', lambda x: x.mean() * 100)\n",
    "]).round(2)\n",
    "print(\"\\nTable 2: PE Incidence Rates by Age Group\")\n",
    "print(pe_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aafb4a0-7b2b-4913-bcdb-94f818874a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chi-Square Test\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chi-square statistic: 24.1489\n",
      "Degrees of freedom: 3\n",
      "P-value: 0.0000\n",
      "Significant at α=0.05: Yes\n"
     ]
    }
   ],
   "source": [
    "#STEP 3: CHI-SQUARE TEST OF INDEPENDENCE\n",
    "\n",
    "print(\"\\n Chi-Square Test\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create contingency table (without margins)\n",
    "contingency = pd.crosstab(\n",
    "    df_clean['Age_Category'], \n",
    "    df_clean['PE_in_index_hospitalization']\n",
    ")\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "# Check assumptions\n",
    "min_expected = expected.min()\n",
    "if min_expected < 5:\n",
    "    print(f\"⚠ WARNING: Minimum expected frequency = {min_expected:.2f} (< 5)\")\n",
    "\n",
    "# Display test results\n",
    "print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant at α=0.05: {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669b7a88-ee8d-428f-bb3c-ffc41dbd7a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 4] Pairwise Comparisons (Bonferroni-corrected)\n",
      "--------------------------------------------------------------------------------\n",
      "Adjusted α: 0.0083\n",
      "\n",
      "    Comparison    Chi2  P-value Significant\n",
      "40-60 vs 60-75  0.1698   0.6803          No\n",
      "  40-60 vs <40 20.3854   0.0000         Yes\n",
      "  40-60 vs >75  0.1494   0.6991          No\n",
      "  60-75 vs <40 14.0171   0.0002         Yes\n",
      "  60-75 vs >75  0.0000   1.0000          No\n",
      "    <40 vs >75 13.6829   0.0002         Yes\n"
     ]
    }
   ],
   "source": [
    "#STEP 4: PAIRWISE COMPARISONS (if omnibus test is significant) \n",
    "if p_value < 0.05:\n",
    "    print(\"\\n[STEP 4] Pairwise Comparisons (Bonferroni-corrected)\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    age_groups = sorted(df_clean['Age_Category'].unique())\n",
    "    n_comparisons = len(list(combinations(age_groups, 2)))\n",
    "    bonferroni_alpha = 0.05 / n_comparisons\n",
    "    \n",
    "    print(f\"Adjusted α: {bonferroni_alpha:.4f}\\n\")\n",
    "    \n",
    "    pairwise_results = []\n",
    "    \n",
    "    for group1, group2 in combinations(age_groups, 2):\n",
    "        subset = df_clean[df_clean['Age_Category'].isin([group1, group2])]\n",
    "        cont_table = pd.crosstab(\n",
    "            subset['Age_Category'],\n",
    "            subset['PE_in_index_hospitalization']\n",
    "        )\n",
    "        chi2_pair, p_pair, _, _ = chi2_contingency(cont_table)\n",
    "        \n",
    "        pairwise_results.append({\n",
    "            'Comparison': f\"{group1} vs {group2}\",\n",
    "            'Chi2': round(chi2_pair, 4),\n",
    "            'P-value': round(p_pair, 4),\n",
    "            'Significant': 'Yes' if p_pair < bonferroni_alpha else 'No'\n",
    "        })\n",
    "    \n",
    "    pairwise_df = pd.DataFrame(pairwise_results)\n",
    "    print(pairwise_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30093cae-8020-472c-9f9e-b2cee4610979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Logistic Regression (Reference: Age <40)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Model Summary:\n",
      "                                Logit Regression Results                               \n",
      "=======================================================================================\n",
      "Dep. Variable:     PE_in_index_hospitalization   No. Observations:                 1712\n",
      "Model:                                   Logit   Df Residuals:                     1708\n",
      "Method:                                    MLE   Df Model:                            3\n",
      "Date:                         Mon, 01 Dec 2025   Pseudo R-squ.:                 0.01024\n",
      "Time:                                 12:55:31   Log-Likelihood:                -1174.5\n",
      "converged:                                True   LL-Null:                       -1186.6\n",
      "Covariance Type:                     nonrobust   LLR p-value:                 2.160e-05\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4526      0.109     -4.157      0.000      -0.666      -0.239\n",
      "Age_40-60      0.6249      0.137      4.560      0.000       0.356       0.893\n",
      "Age_60-75      0.5628      0.148      3.804      0.000       0.273       0.853\n",
      "Age_>75        0.5648      0.150      3.760      0.000       0.270       0.859\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#STEP 5: LOGISTIC REGRESSION MODEL\n",
    "print(\"\\n Logistic Regression (Reference: Age <40)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create dummy variables\n",
    "age_dummies = pd.get_dummies(df_clean['Age_Category'], prefix='Age', drop_first=False)\n",
    "\n",
    "# Drop reference category\n",
    "if 'Age_<40' in age_dummies.columns:\n",
    "    age_dummies = age_dummies.drop('Age_<40', axis=1)\n",
    "\n",
    "# Prepare data\n",
    "y = df_clean['PE_in_index_hospitalization'].astype(float)\n",
    "X = age_dummies.astype(float)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Remove any missing values\n",
    "mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "X_final = X[mask]\n",
    "y_final = y[mask]\n",
    "\n",
    "# Fit logistic regression\n",
    "logit_model = sm.Logit(y_final, X_final)\n",
    "result = logit_model.fit(disp=0)\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c94a0dd-26a9-4967-892a-c3bdcb354519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Odds Ratios with 95% CI\n",
      "--------------------------------------------------------------------------------\n",
      " Variable     OR      95% CI  P_value\n",
      "    const 0.6359 (0.51-0.79)   0.0000\n",
      "Age_40-60 1.8680 (1.43-2.44)   0.0000\n",
      "Age_60-75 1.7555 (1.31-2.35)   0.0001\n",
      "  Age_>75 1.7590 (1.31-2.36)   0.0002\n"
     ]
    }
   ],
   "source": [
    "#STEP 6: ODDS RATIOS (95% CI)\n",
    "\n",
    "print(\"\\n Odds Ratios with 95% CI\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calculate odds ratios\n",
    "or_df = pd.DataFrame({\n",
    "    'Variable': result.params.index,\n",
    "    'OR': np.exp(result.params.values),\n",
    "    'CI_Lower': np.exp(result.conf_int()[0].values),\n",
    "    'CI_Upper': np.exp(result.conf_int()[1].values),\n",
    "    'P_value': result.pvalues.values\n",
    "})\n",
    "\n",
    "# Format for display\n",
    "or_df['95% CI'] = or_df.apply(\n",
    "    lambda row: f\"({row['CI_Lower']:.2f}-{row['CI_Upper']:.2f})\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(or_df[['Variable', 'OR', '95% CI', 'P_value']].round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce59d8c-0934-4356-8e22-aee21d8bb23c",
   "metadata": {},
   "source": [
    "Key Findings:\n",
    "Descriptive Statistics:\n",
    "• PE incidence varies significantly across age groups (χ² = 24.15, p < 0.0001)\n",
    "• Lowest incidence in patients <40 years: 38.87%\n",
    "• Highest incidence in patients 40-60 years: 54.30%\n",
    "• Similar rates in 60-75 (52.75%) and >75 (52.80%) age groups\n",
    "\n",
    "Pairwise Comparisons (Bonferroni-corrected α=0.0083):\n",
    "• Significant differences found between: \n",
    "o  40-60 vs <40: p < 0.0001 \n",
    "o  60-75 vs <40: p = 0.0002 \n",
    "o  >75 vs <40: p = 0.0002 \n",
    "• No significant differences between older age groups (40-60, 60-75, >75)\n",
    "\n",
    "Logistic Regression Results:\n",
    "• Age 40-60: OR = 1.87 (95% CI: 1.43-2.44), p < 0.0001 \n",
    "o  Patients aged 40-60 have 87% higher odds of PE compared to those <40\n",
    "• Age 60-75: OR = 1.76 (95% CI: 1.31-2.35), p = 0.0001 \n",
    "o  Patients aged 60-75 have 76% higher odds of PE compared to those <40\n",
    "• Age >75: OR = 1.76 (95% CI: 1.31-2.36), p = 0.0002 \n",
    "o  Patients aged >75 have 76% higher odds of PE compared to those <40\n",
    "\n",
    "Clinical Interpretation:\n",
    "The risk of PE increases substantially after age 40 and remains elevated throughout older age. \n",
    "The youngest group (<40 years) has significantly lower PE incidence. This suggests that age is an important risk factor for PE, with risk approximately doubling after age 40. \n",
    "The similar odds ratios across the three older age groups (40-60, 60-75, >75) indicate that the increased risk plateaus after age 40 instead of continuing to rise linearly with age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b86a48-10c6-4de1-b36b-dd400dcc33f0",
   "metadata": {},
   "source": [
    "AIM 2: HYPERTENSION AND PE ASSOCIATION (STRATIFIED BY AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8bfb527-f8db-446b-8048-bc654f2c7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: DATA PREPARATION AND CLEANING\n",
    "# Clean column names and prepare data\n",
    "df.columns = df.columns.str.strip()\n",
    "df_clean = df[df['Age_Category'].notna() & \n",
    "              df['PE_in_index_hospitalization'].notna() & \n",
    "              df['Hypertension'].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fd7dfef-d0de-4459-9bb2-4e7106bd9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Overall Hypertension-PE Association\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Table 3: Hypertension × PE Status\n",
      "        PE Negative  PE Positive  Total\n",
      "No HTN          396          376    772\n",
      "HTN             453          487    940\n",
      "Total           849          863   1712\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Overall Hypertension Prevalence by PE Status\n",
    "print(\"\\n Overall Hypertension-PE Association\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Table 3: Overall hypertension prevalence by PE status\n",
    "htn_pe_crosstab = pd.crosstab(\n",
    "    df_clean['Hypertension'], \n",
    "    df_clean['PE_in_index_hospitalization'],\n",
    "    margins=True\n",
    ")\n",
    "htn_pe_crosstab.index = ['No HTN', 'HTN', 'Total']\n",
    "htn_pe_crosstab.columns = ['PE Negative', 'PE Positive', 'Total']\n",
    "\n",
    "print(\"\\nTable 3: Hypertension × PE Status\")\n",
    "print(htn_pe_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eae0e07-a044-4692-846d-d267cd88c515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-square test:\n",
      "  Chi2 = 1.5117, p-value = 0.2189\n",
      "\n",
      " Overall Odds Ratio: 1.13 (95% CI: 0.94-1.37)\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Overall Chi-square test \n",
    "# Create 2x2 contingency table (without margins)\n",
    "contingency_overall = pd.crosstab(\n",
    "    df_clean['Hypertension'],\n",
    "    df_clean['PE_in_index_hospitalization']\n",
    ")\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2_overall, p_overall, dof_overall, expected_overall = chi2_contingency(contingency_overall)\n",
    "\n",
    "print(f\"\\nChi-square test:\")\n",
    "print(f\"  Chi2 = {chi2_overall:.4f}, p-value = {p_overall:.4f}\")\n",
    "\n",
    "# Calculate overall odds ratio using Table2x2\n",
    "table = Table2x2(contingency_overall.values)\n",
    "or_overall = table.oddsratio\n",
    "ci_overall = table.oddsratio_confint()\n",
    "\n",
    "print(f\"\\n Overall Odds Ratio: {or_overall:.2f} (95% CI: {ci_overall[0]:.2f}-{ci_overall[1]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680f7396-d794-4a4e-8f79-827f4bfb4927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Age-Stratified Hypertension-PE Association\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Table 4: Age-Stratified Associations\n",
      "\n",
      "40-60   : OR =  1.23 ( 0.89- 1.71), p = 0.2391\n",
      "60-75   : OR =  1.25 ( 0.84- 1.87), p = 0.3121\n",
      "<40     : OR =  1.00 ( 0.65- 1.53), p = 1.0000\n",
      ">75     : OR =  0.80 ( 0.52- 1.22), p = 0.3473\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Age-Stratified Analysis\n",
    "print(\"\\n Age-Stratified Hypertension-PE Association\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "age_groups = sorted(df_clean['Age_Category'].unique())\n",
    "stratified_results = []\n",
    "\n",
    "print(\"\\nTable 4: Age-Stratified Associations\\n\")\n",
    "\n",
    "for age_group in age_groups:\n",
    "    # Subset data for this age group\n",
    "    subset = df_clean[df_clean['Age_Category'] == age_group]\n",
    "    \n",
    "    # Create contingency table\n",
    "    cont_table = pd.crosstab(\n",
    "        subset['Hypertension'],\n",
    "        subset['PE_in_index_hospitalization']\n",
    "    )\n",
    "    \n",
    "    # Check if we have sufficient data (all cells > 0)\n",
    "    if cont_table.shape == (2, 2) and (cont_table.values > 0).all():\n",
    "        # Chi-square test\n",
    "        chi2_strat, p_strat, _, _ = chi2_contingency(cont_table)\n",
    "        \n",
    "        # Calculate odds ratio\n",
    "        table_strat = Table2x2(cont_table.values)\n",
    "        or_strat = table_strat.oddsratio\n",
    "        ci_strat = table_strat.oddsratio_confint()\n",
    "        \n",
    "        stratified_results.append({\n",
    "            'Age_Group': age_group,\n",
    "            'N': len(subset),\n",
    "            'OR': or_strat,\n",
    "            'CI_Lower': ci_strat[0],\n",
    "            'CI_Upper': ci_strat[1],\n",
    "            'P_value': p_strat\n",
    "        })\n",
    "        \n",
    "        print(f\"{age_group:8s}: OR = {or_strat:5.2f} ({ci_strat[0]:5.2f}-{ci_strat[1]:5.2f}), p = {p_strat:.4f}\")\n",
    "    else:\n",
    "        print(f\"{age_group:8s}: Insufficient data for analysis\")\n",
    "\n",
    "# Create results dataframe\n",
    "stratified_df = pd.DataFrame(stratified_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd3c29e2-427b-4952-a866-8f51fd5a2446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Logistic Regression with Interaction Term\n",
      "--------------------------------------------------------------------------------\n",
      "Model: logit(PE) = β₀ + β₁(HTN) + β₂(Age) + β₃(Sex) + β₄(HTN×Age)\n",
      "\n",
      " Model Summary:\n",
      "                                Logit Regression Results                               \n",
      "=======================================================================================\n",
      "Dep. Variable:     PE_in_index_hospitalization   No. Observations:                 1712\n",
      "Model:                                   Logit   Df Residuals:                     1703\n",
      "Method:                                    MLE   Df Model:                            8\n",
      "Date:                         Mon, 01 Dec 2025   Pseudo R-squ.:                 0.01405\n",
      "Time:                                 12:55:31   Log-Likelihood:                -1169.9\n",
      "converged:                                True   LL-Null:                       -1186.6\n",
      "Covariance Type:                     nonrobust   LLR p-value:                 5.325e-05\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const              -0.5494      0.152     -3.605      0.000      -0.848      -0.251\n",
      "Hypertension        0.0249      0.220      0.113      0.910      -0.406       0.456\n",
      "Sex                 0.2238      0.099      2.262      0.024       0.030       0.418\n",
      "Age_40-60           0.4902      0.189      2.594      0.009       0.120       0.861\n",
      "Age_60-75           0.4030      0.215      1.875      0.061      -0.018       0.824\n",
      "Age_>75             0.7070      0.229      3.087      0.002       0.258       1.156\n",
      "HTN_x_Age_40-60     0.1850      0.276      0.670      0.503      -0.356       0.726\n",
      "HTN_x_Age_60-75     0.2125      0.300      0.708      0.479      -0.376       0.801\n",
      "HTN_x_Age_>75      -0.2340      0.310     -0.756      0.450      -0.841       0.373\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Logistic Regression with Interaction Term \n",
    "print(\"\\n Logistic Regression with Interaction Term\")\n",
    "print(\"-\"*80)\n",
    "print(\"Model: logit(PE) = β₀ + β₁(HTN) + β₂(Age) + β₃(Sex) + β₄(HTN×Age)\")\n",
    "\n",
    "# Create dummy variables for age (reference: <40)\n",
    "age_dummies = pd.get_dummies(df_clean['Age_Category'], prefix='Age', drop_first=False)\n",
    "if 'Age_<40' in age_dummies.columns:\n",
    "    age_dummies = age_dummies.drop('Age_<40', axis=1)\n",
    "\n",
    "# Create interaction terms: Hypertension × Age Category\n",
    "interaction_terms = pd.DataFrame()\n",
    "for col in age_dummies.columns:\n",
    "    interaction_terms[f'HTN_x_{col}'] = df_clean['Hypertension'] * age_dummies[col]\n",
    "\n",
    "# Prepare predictors\n",
    "X = pd.concat([\n",
    "    df_clean[['Hypertension', 'Sex']].replace({'Female': 0, 'Male': 1}),\n",
    "    age_dummies,\n",
    "    interaction_terms\n",
    "], axis=1)\n",
    "\n",
    "# Prepare outcome\n",
    "y = df_clean['PE_in_index_hospitalization'].astype(float)\n",
    "\n",
    "# Convert all to float\n",
    "X = X.astype(float)\n",
    "\n",
    "# Add constant\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Remove missing values\n",
    "mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "X_final = X[mask]\n",
    "y_final = y[mask]\n",
    "\n",
    "# Fit model\n",
    "logit_model = sm.Logit(y_final, X_final)\n",
    "result = logit_model.fit(disp=0)\n",
    "\n",
    "print(\"\\n Model Summary:\")\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a07892a-8a2d-4c0a-86dd-e6a9661d6372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test for Effect Modification (Interaction)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Interaction Term P-values:\n",
      "  HTN × 40-60: p = 0.5027 (Not significant at α=0.10)\n",
      "  HTN × 60-75: p = 0.4788 (Not significant at α=0.10)\n",
      "  HTN × >75: p = 0.4496 (Not significant at α=0.10)\n",
      "\n",
      "Minimum interaction p-value: 0.4496\n",
      "No strong evidence of effect modification (all interactions p ≥ 0.10)\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Test for Effect Modification\n",
    "\n",
    "print(\"\\n Test for Effect Modification (Interaction)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Extract p-values for interaction terms\n",
    "interaction_vars = [col for col in result.params.index if 'HTN_x_' in col]\n",
    "interaction_pvalues = result.pvalues[interaction_vars]\n",
    "\n",
    "print(\"\\nInteraction Term P-values:\")\n",
    "for var, pval in zip(interaction_vars, interaction_pvalues):\n",
    "    age_cat = var.replace('HTN_x_Age_', '')\n",
    "    sig = \"Significant\" if pval < 0.10 else \"Not significant\"\n",
    "    print(f\"  HTN × {age_cat}: p = {pval:.4f} ({sig} at α=0.10)\")\n",
    "\n",
    "# Overall interaction test (likelihood ratio test would be ideal)\n",
    "min_interaction_p = interaction_pvalues.min()\n",
    "print(f\"\\nMinimum interaction p-value: {min_interaction_p:.4f}\")\n",
    "\n",
    "if min_interaction_p < 0.10:\n",
    "    print(\"Evidence of effect modification detected (at least one interaction p < 0.10)\")\n",
    "else:\n",
    "    print(\"No strong evidence of effect modification (all interactions p ≥ 0.10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a471ea4-8020-4d14-bae0-b46bb8e5f752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Odds Ratios from Full Model\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Main Effects:\n",
      "    Variable     OR      95% CI  P_value\n",
      "       const 0.5773 (0.43-0.78)   0.0003\n",
      "Hypertension 1.0252 (0.67-1.58)   0.9097\n",
      "         Sex 1.2508 (1.03-1.52)   0.0237\n",
      "   Age_40-60 1.6327 (1.13-2.36)   0.0095\n",
      "   Age_60-75 1.4964 (0.98-2.28)   0.0607\n",
      "     Age_>75 2.0279 (1.29-3.18)   0.0020\n",
      "\n",
      "Interaction Terms:\n",
      "       Variable     OR      95% CI  P_value\n",
      "HTN_x_Age_40-60 1.2033 (0.70-2.07)   0.5027\n",
      "HTN_x_Age_60-75 1.2368 (0.69-2.23)   0.4788\n",
      "  HTN_x_Age_>75 0.7914 (0.43-1.45)   0.4496\n"
     ]
    }
   ],
   "source": [
    "#STEP 6: ODDS RATIOS (95% CI)\n",
    "\n",
    "print(\"\\n Odds Ratios from Full Model\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calculate odds ratios\n",
    "or_df = pd.DataFrame({\n",
    "    'Variable': result.params.index,\n",
    "    'OR': np.exp(result.params.values),\n",
    "    'CI_Lower': np.exp(result.conf_int()[0].values),\n",
    "    'CI_Upper': np.exp(result.conf_int()[1].values),\n",
    "    'P_value': result.pvalues.values\n",
    "})\n",
    "\n",
    "# Format for display\n",
    "or_df['95% CI'] = or_df.apply(\n",
    "    lambda row: f\"({row['CI_Lower']:.2f}-{row['CI_Upper']:.2f})\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display main effects and interactions separately\n",
    "print(\"\\nMain Effects:\")\n",
    "main_effects = or_df[~or_df['Variable'].str.contains('HTN_x_', na=False)]\n",
    "print(main_effects[['Variable', 'OR', '95% CI', 'P_value']].round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\nInteraction Terms:\")\n",
    "interactions = or_df[or_df['Variable'].str.contains('HTN_x_', na=False)]\n",
    "if len(interactions) > 0:\n",
    "    print(interactions[['Variable', 'OR', '95% CI', 'P_value']].round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1853b60b-94b8-4f6d-899d-da41abc7df6f",
   "metadata": {},
   "source": [
    "Key Findings:\n",
    "\n",
    "Overall Association:\n",
    "• No significant overall association between hypertension and PE\n",
    "• Overall OR = 1.13 (95% CI: 0.94-1.37), χ² = 1.51, p = 0.219\n",
    "• 48.7% of PE-negative patients had hypertension\n",
    "• 56.4% of PE-positive patients had hypertension\n",
    "\n",
    "Age-Stratified Analysis: None of the age groups showed significant associations:\n",
    "• Age 40-60: OR = 1.23 (0.89-1.71), p = 0.239\n",
    "• Age 60-75: OR = 1.25 (0.84-1.87), p = 0.312\n",
    "• Age <40: OR = 1.00 (0.65-1.53), p = 1.000\n",
    "• Age >75: OR = 0.80 (0.52-1.22), p = 0.347\n",
    "\n",
    "Interaction Analysis:\n",
    "• No evidence of effect modification by age (all interaction p-values > 0.10)\n",
    "• HTN × 40-60: p = 0.503\n",
    "• HTN × 60-75: p = 0.479\n",
    "• HTN × >75: p = 0.450\n",
    "\n",
    "Full Model Results:\n",
    "• Sex: OR = 1.25 (1.03-1.52), p = 0.024 \n",
    "o  Males have 25% higher odds of PE than females\n",
    "• Hypertension main effect: OR = 1.03 (0.67-1.58), p = 0.910 \n",
    "o  No significant independent effect of hypertension\n",
    "\n",
    "Clinical Interpretation:\n",
    "Hypertension is not independently associated with PE diagnosis in this population after adjusting for age and sex. The relationship between hypertension and PE does not vary by age group, suggesting that age does not modify the hypertension-PE relationship. \n",
    "However, male sex emerged as a significant predictor, with males having 25% higher odds of PE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b9c8c-924c-42cb-b1e1-d9e88d002e7a",
   "metadata": {},
   "source": [
    "AIM 3: RACIAL/ETHNIC DISPARITIES IN DIAGNOSTIC INTENSITY (PE+PATIENTS ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8015abee-4e6d-4d46-8058-22db46a2341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data Preparation - PE+ Patients Only\n",
      "--------------------------------------------------------------------------------\n",
      "Total PE+ patients: 863\n",
      "\n",
      "Race/Ethnicity Distribution:\n",
      "Race_Ethnicity\n",
      "Non-Hispanic White    693\n",
      "Non-Hispanic Black     89\n",
      "Other/Unknown          45\n",
      "Non-Hispanic Asian     20\n",
      "Hispanic/Latinx        16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Groups with n<10:\n",
      "None - all groups have adequate sample size\n"
     ]
    }
   ],
   "source": [
    "#STEP 1: DATA PREPARATION - PE + PATIENTS ONLY\n",
    "print(\"\\n Data Preparation - PE+ Patients Only\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Filter to PE-positive patients only\n",
    "df_pe_pos = df[df['PE_in_index_hospitalization'] == 1].copy()\n",
    "\n",
    "print(f\"Total PE+ patients: {len(df_pe_pos)}\")\n",
    "\n",
    "# Check Race_Ethnicity distribution\n",
    "print(\"\\nRace/Ethnicity Distribution:\")\n",
    "race_counts = df_pe_pos['Race_Ethnicity'].value_counts()\n",
    "print(race_counts)\n",
    "\n",
    "# Identify small groups (n<10) that may need collapsing\n",
    "print(\"\\nGroups with n<10:\")\n",
    "small_groups = race_counts[race_counts < 10]\n",
    "if len(small_groups) > 0:\n",
    "    print(small_groups)\n",
    "    print(\"\\nConsider collapsing these into 'Other/Unknown' category\")\n",
    "else:\n",
    "    print(\"None - all groups have adequate sample size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3abfffe-07ec-4b68-99da-a32b7eca6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distribution of Additional Procedures\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Overall Distribution:\n",
      "count    863.000000\n",
      "mean       0.504056\n",
      "std        0.525162\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.000000\n",
      "max        2.000000\n",
      "Name: Additional_Procedures, dtype: float64\n",
      "\n",
      "Value counts:\n",
      "Additional_Procedures\n",
      "0    439\n",
      "1    413\n",
      "2     11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mean: 0.5041\n",
      "Variance: 0.2758\n",
      "No overdispersion (variance ≤ mean)\n",
      "→ Poisson regression may be appropriate\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Examine Distribution of Additional Procedures\n",
    "print(\"\\n Distribution of Additional Procedures\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nOverall Distribution:\")\n",
    "print(df_pe_pos['Additional_Procedures'].describe())\n",
    "\n",
    "print(f\"\\nValue counts:\")\n",
    "print(df_pe_pos['Additional_Procedures'].value_counts().sort_index())\n",
    "\n",
    "# Check for overdispersion\n",
    "mean_proc = df_pe_pos['Additional_Procedures'].mean()\n",
    "var_proc = df_pe_pos['Additional_Procedures'].var()\n",
    "print(f\"\\nMean: {mean_proc:.4f}\")\n",
    "print(f\"Variance: {var_proc:.4f}\")\n",
    "\n",
    "if var_proc > mean_proc:\n",
    "    print(f\"Overdispersion detected (variance > mean)\")\n",
    "    print(\"→ Negative binomial regression recommended\")\n",
    "else:\n",
    "    print(f\"No overdispersion (variance ≤ mean)\")\n",
    "    print(\"→ Poisson regression may be appropriate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6084173-dc3c-49bb-96d3-bc89324bd123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Descriptive Statistics by Race/Ethnicity\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Table 5: Additional Procedures by Race/Ethnicity\n",
      "                      N   Mean     SD  Median   Q1   Q3\n",
      "Race_Ethnicity                                         \n",
      "Hispanic/Latinx      16  0.562  0.629     0.5  0.0  1.0\n",
      "Non-Hispanic Asian   20  0.650  0.489     1.0  0.0  1.0\n",
      "Non-Hispanic Black   89  0.483  0.546     0.0  0.0  1.0\n",
      "Non-Hispanic White  693  0.504  0.520     0.0  0.0  1.0\n",
      "Other/Unknown        45  0.467  0.548     0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Descriptive Statistics by Race/Ethnicity\n",
    "print(\"\\n Descriptive Statistics by Race/Ethnicity\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Table 5: Descriptive statistics of additional procedures by race/ethnicity\n",
    "print(\"\\nTable 5: Additional Procedures by Race/Ethnicity\")\n",
    "\n",
    "race_stats = df_pe_pos.groupby('Race_Ethnicity')['Additional_Procedures'].agg([\n",
    "    ('N', 'count'),\n",
    "    ('Mean', 'mean'),\n",
    "    ('SD', 'std'),\n",
    "    ('Median', 'median'),\n",
    "    ('Q1', lambda x: x.quantile(0.25)),\n",
    "    ('Q3', lambda x: x.quantile(0.75))\n",
    "]).round(3)\n",
    "\n",
    "print(race_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70733794-51d9-4f3a-ab98-398dd306f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assumptions Testing\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Shapiro-Wilk Test for Normality:\n",
      "    Race/Ethnicity        W      P_value Normal\n",
      "Non-Hispanic White 0.671069 1.615629e-34     No\n",
      "     Other/Unknown 0.688492 1.750343e-08     No\n",
      "   Hispanic/Latinx 0.750202 6.388482e-04     No\n",
      "Non-Hispanic Black 0.690434 2.100851e-12     No\n",
      "Non-Hispanic Asian 0.607649 3.537657e-06     No\n",
      "\n",
      "Levene's Test for Homogeneity of Variance:\n",
      "  Levene statistic: 0.5447\n",
      "  P-value: 0.7029\n",
      "  Equal variances: Yes\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Test for Normality and Homogeneity of Variance\n",
    "print(\"\\n Assumptions Testing\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Test normality for each race/ethnicity group\n",
    "print(\"\\nShapiro-Wilk Test for Normality:\")\n",
    "race_groups = df_pe_pos['Race_Ethnicity'].unique()\n",
    "normality_results = []\n",
    "\n",
    "for race in race_groups:\n",
    "    data = df_pe_pos[df_pe_pos['Race_Ethnicity'] == race]['Additional_Procedures'].dropna()\n",
    "    if len(data) >= 3:  # Shapiro test requires at least 3 observations\n",
    "        stat, p = shapiro(data)\n",
    "        normality_results.append({\n",
    "            'Race/Ethnicity': race,\n",
    "            'W': stat,\n",
    "            'P_value': p,\n",
    "            'Normal': 'Yes' if p > 0.05 else 'No'\n",
    "        })\n",
    "\n",
    "normality_df = pd.DataFrame(normality_results)\n",
    "print(normality_df.to_string(index=False))\n",
    "\n",
    "# Test homogeneity of variances (Levene's test)\n",
    "print(\"\\nLevene's Test for Homogeneity of Variance:\")\n",
    "race_data = [df_pe_pos[df_pe_pos['Race_Ethnicity'] == race]['Additional_Procedures'].dropna() \n",
    "             for race in race_groups if len(df_pe_pos[df_pe_pos['Race_Ethnicity'] == race]) >= 2]\n",
    "\n",
    "if len(race_data) >= 2:\n",
    "    levene_stat, levene_p = levene(*race_data)\n",
    "    print(f\"  Levene statistic: {levene_stat:.4f}\")\n",
    "    print(f\"  P-value: {levene_p:.4f}\")\n",
    "    print(f\"  Equal variances: {'Yes' if levene_p > 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d03438da-29bd-4fd1-b3bd-37fe3940ffe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Kruskal-Wallis H Test\n",
      "--------------------------------------------------------------------------------\n",
      "Kruskal-Wallis H statistic: 2.3934\n",
      "P-value: 0.6638\n",
      "Significant at α=0.05: No\n",
      "\n",
      "→ No significant differences in diagnostic intensity across racial/ethnic groups\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Kruskal-Wallis test (Non-parametric)\n",
    "print(\"\\n Kruskal-Wallis H Test\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "kw_stat, kw_p = kruskal(*race_data)\n",
    "\n",
    "print(f\"Kruskal-Wallis H statistic: {kw_stat:.4f}\")\n",
    "print(f\"P-value: {kw_p:.4f}\")\n",
    "print(f\"Significant at α=0.05: {'Yes' if kw_p < 0.05 else 'No'}\")\n",
    "\n",
    "if kw_p < 0.05:\n",
    "    print(\"\\n→ Significant differences detected in diagnostic intensity across racial/ethnic groups\")\n",
    "    print(\"  Post-hoc tests recommended (e.g., Dunn's test with Bonferroni correction)\")\n",
    "else:\n",
    "    print(\"\\n→ No significant differences in diagnostic intensity across racial/ethnic groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92595fdc-6ea1-4ee9-93db-ab148459b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Excessive Diagnostics (>1 Additional Procedure)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Table 6: Excessive Diagnostics by Race/Ethnicity\n",
      "                      N  Excessive_N  Percentage\n",
      "Race_Ethnicity                                  \n",
      "Hispanic/Latinx      16            1        6.25\n",
      "Non-Hispanic Asian   20            0        0.00\n",
      "Non-Hispanic Black   89            2        2.25\n",
      "Non-Hispanic White  693            7        1.01\n",
      "Other/Unknown        45            1        2.22\n",
      "\n",
      "Chi-square Test for Excessive Diagnostics:\n",
      "  Chi-square statistic: 4.7811\n",
      "  P-value: 0.3105\n",
      "  Significant at α=0.05: No\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Excessive Diagnostics by Race/Ethnicity\n",
    "print(\"\\n Excessive Diagnostics (>1 Additional Procedure)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Table 6: Proportion with excessive diagnostics by race/ethnicity\n",
    "print(\"\\nTable 6: Excessive Diagnostics by Race/Ethnicity\")\n",
    "\n",
    "excessive_stats = df_pe_pos.groupby('Race_Ethnicity')['Excessive_Diagnostics'].agg([\n",
    "    ('N', 'count'),\n",
    "    ('Excessive_N', 'sum'),\n",
    "    ('Percentage', lambda x: x.mean() * 100)\n",
    "]).round(2)\n",
    "\n",
    "print(excessive_stats)\n",
    "\n",
    "# Chi-square test for excessive diagnostics\n",
    "print(\"\\nChi-square Test for Excessive Diagnostics:\")\n",
    "contingency_excessive = pd.crosstab(\n",
    "    df_pe_pos['Race_Ethnicity'],\n",
    "    df_pe_pos['Excessive_Diagnostics']\n",
    ")\n",
    "\n",
    "chi2_exc, p_exc, dof_exc, expected_exc = chi2_contingency(contingency_excessive)\n",
    "\n",
    "print(f\"  Chi-square statistic: {chi2_exc:.4f}\")\n",
    "print(f\"  P-value: {p_exc:.4f}\")\n",
    "print(f\"  Significant at α=0.05: {'Yes' if p_exc < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe0052ea-e1c7-42ff-8bc9-6eed635829b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Negative Binomial Regression (Adjusted)\n",
      "--------------------------------------------------------------------------------\n",
      "Model: log(Additional_Procedures) = β₀ + β₁(Race) + β₂(Age) + β₃(Sex) + β₄(HTN)\n",
      "\n",
      "Model Summary:\n",
      "                   Generalized Linear Model Regression Results                   \n",
      "=================================================================================\n",
      "Dep. Variable:     Additional_Procedures   No. Observations:                  863\n",
      "Model:                               GLM   Df Residuals:                      853\n",
      "Model Family:           NegativeBinomial   Df Model:                            9\n",
      "Link Function:                       Log   Scale:                          1.0000\n",
      "Method:                             IRLS   Log-Likelihood:                -826.89\n",
      "Date:                   Mon, 01 Dec 2025   Deviance:                       466.69\n",
      "Time:                           12:55:32   Pearson chi2:                     314.\n",
      "No. Iterations:                        5   Pseudo R-squ. (CS):           0.002116\n",
      "Covariance Type:               nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -0.7163      0.177     -4.057      0.000      -1.062      -0.370\n",
      "Race_Hispanic/Latinx        0.1102      0.422      0.261      0.794      -0.717       0.938\n",
      "Race_Non-Hispanic Asian     0.2759      0.366      0.755      0.450      -0.440       0.992\n",
      "Race_Non-Hispanic Black    -0.0365      0.201     -0.182      0.855      -0.430       0.356\n",
      "Race_Other/Unknown         -0.0405      0.277     -0.146      0.884      -0.582       0.502\n",
      "Age_40-60                   0.0482      0.183      0.264      0.792      -0.310       0.406\n",
      "Age_60-75                   0.0915      0.195      0.469      0.639      -0.290       0.473\n",
      "Age_>75                    -0.0354      0.199     -0.177      0.859      -0.426       0.356\n",
      "Sex                        -0.0690      0.119     -0.578      0.563      -0.303       0.165\n",
      "Hypertension                0.0512      0.121      0.423      0.672      -0.186       0.288\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Git Hub\\PE-EHR-Study\\.venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Negative Binomial Regression (Adjusted Analysis)\n",
    "print(\"\\n Negative Binomial Regression (Adjusted)\")\n",
    "print(\"-\"*80)\n",
    "print(\"Model: log(Additional_Procedures) = β₀ + β₁(Race) + β₂(Age) + β₃(Sex) + β₄(HTN)\")\n",
    "\n",
    "# Prepare data - remove missing values\n",
    "df_nb = df_pe_pos[['Additional_Procedures', 'Race_Ethnicity', 'Age_Category', \n",
    "                    'Sex', 'Hypertension']].copy()\n",
    "df_nb = df_nb.dropna()\n",
    "\n",
    "# Create dummy variables for race/ethnicity (reference: Non-Hispanic White)\n",
    "race_dummies = pd.get_dummies(df_nb['Race_Ethnicity'], prefix='Race', drop_first=False)\n",
    "if 'Race_Non-Hispanic White' in race_dummies.columns:\n",
    "    race_dummies = race_dummies.drop('Race_Non-Hispanic White', axis=1)\n",
    "\n",
    "# Create dummy variables for age (reference: <40)\n",
    "age_dummies = pd.get_dummies(df_nb['Age_Category'], prefix='Age', drop_first=False)\n",
    "if 'Age_<40' in age_dummies.columns:\n",
    "    age_dummies = age_dummies.drop('Age_<40', axis=1)\n",
    "\n",
    "# Prepare predictors\n",
    "X = pd.concat([\n",
    "    race_dummies,\n",
    "    age_dummies,\n",
    "    df_nb[['Sex']].replace({'Female': 0, 'Male': 1}),\n",
    "    df_nb[['Hypertension']]\n",
    "], axis=1)\n",
    "\n",
    "# Prepare outcome\n",
    "y = df_nb['Additional_Procedures']\n",
    "\n",
    "# Convert to float\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Add constant\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit negative binomial regression\n",
    "nb_model = sm.GLM(y, X, family=sm.families.NegativeBinomial())\n",
    "nb_result = nb_model.fit()\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(nb_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f003cc-f696-4931-a62f-afe8ea3518c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Incidence Rate Ratios with 95% CI\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Table 7: Adjusted Incidence Rate Ratios (Reference: Non-Hispanic White)\n",
      "               Variable    IRR      95% CI  P_value\n",
      "   Race_Hispanic/Latinx 1.1165 (0.49-2.55)   0.7941\n",
      "Race_Non-Hispanic Asian 1.3178 (0.64-2.70)   0.4503\n",
      "Race_Non-Hispanic Black 0.9641 (0.65-1.43)   0.8554\n",
      "     Race_Other/Unknown 0.9603 (0.56-1.65)   0.8837\n",
      "\n",
      "Covariates:\n",
      "    Variable    IRR      95% CI  P_value\n",
      "   Age_40-60 1.0493 (0.73-1.50)   0.7921\n",
      "   Age_60-75 1.0958 (0.75-1.61)   0.6387\n",
      "     Age_>75 0.9652 (0.65-1.43)   0.8591\n",
      "         Sex 0.9333 (0.74-1.18)   0.5633\n",
      "Hypertension 1.0526 (0.83-1.33)   0.6719\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: Incidence Rate Ratios (IRR)\n",
    "print(\"\\n Incidence Rate Ratios with 95% CI\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calculate IRRs\n",
    "irr_df = pd.DataFrame({\n",
    "    'Variable': nb_result.params.index,\n",
    "    'IRR': np.exp(nb_result.params.values),\n",
    "    'CI_Lower': np.exp(nb_result.conf_int()[0].values),\n",
    "    'CI_Upper': np.exp(nb_result.conf_int()[1].values),\n",
    "    'P_value': nb_result.pvalues.values\n",
    "})\n",
    "\n",
    "# Format for display\n",
    "irr_df['95% CI'] = irr_df.apply(\n",
    "    lambda row: f\"({row['CI_Lower']:.2f}-{row['CI_Upper']:.2f})\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display race/ethnicity results\n",
    "print(\"\\nTable 7: Adjusted Incidence Rate Ratios (Reference: Non-Hispanic White)\")\n",
    "race_vars = irr_df[irr_df['Variable'].str.contains('Race_', na=False)]\n",
    "if len(race_vars) > 0:\n",
    "    print(race_vars[['Variable', 'IRR', '95% CI', 'P_value']].round(4).to_string(index=False))\n",
    "\n",
    "# Display covariates\n",
    "print(\"\\nCovariates:\")\n",
    "covariates = irr_df[~irr_df['Variable'].str.contains('Race_', na=False) & \n",
    "                    (irr_df['Variable'] != 'const')]\n",
    "print(covariates[['Variable', 'IRR', '95% CI', 'P_value']].round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb00f6-4f45-498f-a999-3f613aac2d59",
   "metadata": {},
   "source": [
    "Key Findings:\n",
    "\n",
    "Sample Characteristics (n=863 PE+ patients):\n",
    "• Non-Hispanic White: 693 (80.3%)\n",
    "• Non-Hispanic Black: 89 (10.3%)\n",
    "• Other/Unknown: 45 (5.2%)\n",
    "• Non-Hispanic Asian: 20 (2.3%)\n",
    "• Hispanic/Latinx: 16 (1.9%)\n",
    "\n",
    "Distribution of Additional Procedures:\n",
    "• Mean: 0.50 procedures (SD = 0.53)\n",
    "• Most patients (50.8%) received 0 additional procedures\n",
    "• 47.9% received 1 additional procedure\n",
    "• Only 1.3% received >1 additional procedure (excessive diagnostics)\n",
    "• No overdispersion detected (variance = 0.28 < mean = 0.50)\n",
    "\n",
    "Descriptive Statistics by Race/Ethnicity:\n",
    "• Non-Hispanic Asian: Mean = 0.65 (highest)\n",
    "• Hispanic/Latinx: Mean = 0.56\n",
    "• Non-Hispanic White: Mean = 0.50\n",
    "• Non-Hispanic Black: Mean = 0.48\n",
    "• Other/Unknown: Mean = 0.47 (lowest)\n",
    "\n",
    "Statistical Tests:\n",
    "• Kruskal-Wallis Test: H = 2.39, p = 0.664 (not significant) \n",
    "o  No significant differences in diagnostic intensity across racial/ethnic groups\n",
    "• Chi-square for Excessive Diagnostics: χ² = 4.78, p = 0.311 (not significant) \n",
    "o  Excessive diagnostics rates: \n",
    "    Hispanic/Latinx: 6.25% (highest, but n=1 patient)\n",
    "    Non-Hispanic Black: 2.25%\n",
    "    Other/Unknown: 2.22%\n",
    "    Non-Hispanic White: 1.01%\n",
    "    Non-Hispanic Asian: 0.00%\n",
    "\n",
    "Adjusted Negative Binomial Regression (IRRs): \n",
    "All racial/ethnic groups showed no significant differences compared to Non-Hispanic White:\n",
    "• Hispanic/Latinx: IRR = 1.12 (0.49-2.55), p = 0.794\n",
    "• Non-Hispanic Asian: IRR = 1.32 (0.64-2.70), p = 0.450\n",
    "• Non-Hispanic Black: IRR = 0.96 (0.65-1.43), p = 0.855\n",
    "• Other/Unknown: IRR = 0.96 (0.56-1.65), p = 0.884\n",
    "\n",
    "Covariates:\n",
    "• Age, sex, and hypertension were not significantly associated with diagnostic intensity\n",
    "\n",
    "Clinical Interpretation:\n",
    "After adjusting for age, sex, and hypertension, there were no significant differences in the number of additional diagnostic procedures performed across racial/ethnic groups. This suggests:\n",
    "1. Equitable diagnostic practices: Once PE is suspected enough to warrant testing, diagnostic workup intensity appears similar across racial/ethnic groups\n",
    "2. Appropriate resource utilisation: The low rate of excessive diagnostics (1.3%) suggests clinicians are following evidence-based guidelines and not over-testing\n",
    "3. CTPA as gold standard: Most patients received CTPA (the gold standard), with additional procedures used judiciously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
